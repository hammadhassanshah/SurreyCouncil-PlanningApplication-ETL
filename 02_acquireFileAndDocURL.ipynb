{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "from urllib.parse import urljoin, urlparse\n",
    "import pandas as pd\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_driver(headless=False):\n",
    "    opts = webdriver.ChromeOptions()\n",
    "    if headless:\n",
    "        # Try new headless; if your Chrome is older, change to --headless\n",
    "        opts.add_argument(\"--headless=new\")\n",
    "    opts.add_argument(\"--disable-gpu\")\n",
    "    opts.add_argument(\"--no-sandbox\")\n",
    "    opts.add_argument(\"--window-size=1400,1000\")\n",
    "    return webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()), options=opts)\n",
    "\n",
    "def selenium_to_requests_session(driver):\n",
    "    s = requests.Session()\n",
    "    for c in driver.get_cookies():\n",
    "        s.cookies.set(c[\"name\"], c[\"value\"], domain=c.get(\"domain\"), path=c.get(\"path\", \"/\"))\n",
    "    s.headers.update({\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120 Safari/537.36\"\n",
    "    })\n",
    "    return s\n",
    "\n",
    "def safe_filename(name: str) -> str:\n",
    "    name = re.sub(r\"[\\\\/:*?\\\"<>|]+\", \"_\", name)\n",
    "    name = re.sub(r\"\\s+\", \" \", name).strip()\n",
    "    return name[:180]\n",
    "\n",
    "def is_doc_href(href: str) -> bool:\n",
    "    if not href:\n",
    "        return False\n",
    "    hl = href.lower()\n",
    "    if hl.endswith(COMMON_FILE_EXTS):\n",
    "        return True\n",
    "    # Portals sometimes use no extensions; allow common indicators\n",
    "    return any(k in hl for k in [\"document\", \"download\", \"file\", \"getfile\", \"attachment\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  application_number                                               file_name  \\\n",
      "0       2025/975/TPO                          Application Details - IMG_1961   \n",
      "1       2025/975/TPO                          Application Details - IMG_1957   \n",
      "2       2025/975/TPO                          Application Details - IMG_1960   \n",
      "3       2025/975/TPO                               Application Details - T25   \n",
      "4       2025/975/TPO  Statement of reasons for work - tree details and works   \n",
      "5       2025/975/TPO       Application Details - ApplicationFormRedacted.pdf   \n",
      "6      2025/1032/TPO       Application Details - ApplicationFormRedacted.pdf   \n",
      "\n",
      "                                                                            url  \n",
      "0  https://plandocs.tandridge.gov.uk/my-requests/document-viewer?DocNo=25375147  \n",
      "1  https://plandocs.tandridge.gov.uk/my-requests/document-viewer?DocNo=25375145  \n",
      "2  https://plandocs.tandridge.gov.uk/my-requests/document-viewer?DocNo=25375146  \n",
      "3  https://plandocs.tandridge.gov.uk/my-requests/document-viewer?DocNo=25375144  \n",
      "4  https://plandocs.tandridge.gov.uk/my-requests/document-viewer?DocNo=25368302  \n",
      "5  https://plandocs.tandridge.gov.uk/my-requests/document-viewer?DocNo=25368298  \n",
      "6  https://plandocs.tandridge.gov.uk/my-requests/document-viewer?DocNo=25374197  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from urllib.parse import urljoin, urlparse\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "\n",
    "## first 100 to 200\n",
    "# app_ids = ['2025/298']\n",
    "# app_ids = ['2025/975/TPO', '2025/1032/TPO']\n",
    "# '2025/298', '2025/222', '2024/1032', '2025/284', '2025/291', '2025/279/TPO', '2025/185', '2025/165', '2025/126', '2025/151', '2025/293', '2024/1200', '2025/367/NH', '2025/282', '2025/280', '2025/275', '2025/252', '2025/239', '2025/213', '2025/98', '2025/301/NH', '2025/273/TPO', '2025/271/TPO', '2025/238', '2025/152', '2024/1162', '2025/267/TPO', '2025/156', '2025/260', '2025/258/NC', '2025/229', '2025/195', '2024/1375', '2025/285', '2025/248/TPO', '2025/251/TPO', '2025/225', '2025/81', '2024/1321', '2025/244', '2025/246', '2025/221', '2025/44', '2024/1383', '2025/237/TPO', '2024/348/Cond1', '2025/235', '2025/198', '2025/191', '2025/88', '2024/1373', '2023/186/Cond1', '2025/231', '2025/189', '2025/149', '2024/1326', '2025/228/TPO', '2025/227', '2025/203', '2025/158', '2025/159', '2025/294', '2025/224', '2025/223', '2025/175', '2024/1308', '2025/220/TPO', '2025/122', '2024/1034', '2025/210', '2025/211', '2025/212/TPO', '2025/150', '2025/45', '2024/685', '2025/250/NH', '2024/1259', '2025/265/TCA', '2021/1800/Cond6', '2024/503/Cond2', '2024/697/Cond2', '2025/254/TCA', '2025/199/TPO', '2025/160', '2025/145', '2024/1289', '2024/977/Cond1', '2025/117', '2025/116', '2025/86', '2025/242/NH', '2025/196/NC', '2024/420/Cond2', '2025/120', '2025/70', '2025/331', '2025/247/NH', '2025/240/TCA', '2025/193/TCA', '2025/184/TPO'\n",
    "# ]\n",
    "SKIP_WORDS = {\"plan\", \"plans\"}  # exclude these anywhere in the file name (case-insensitive)\n",
    "\n",
    "def should_skip(name: str) -> bool:\n",
    "    n = (name or \"\").lower()\n",
    "    if \"skip to main content\" in n:\n",
    "        return True\n",
    "    return any(sw in n for sw in SKIP_WORDS)\n",
    "\n",
    "rows = []  # each row: {\"application_number\": ..., \"file_name\": ..., \"url\": ...}\n",
    "\n",
    "for app_id in app_ids:\n",
    "    APP_URL = f\"https://plandocs.tandridge.gov.uk/planning/planning-documents?SDescription={app_id}\"\n",
    "    driver = build_driver(headless=True)  # or False to watch it\n",
    "    try:\n",
    "        driver.get(APP_URL)\n",
    "\n",
    "        # Wait for anchors to stabilize (robust against dynamic loads)\n",
    "        prev_count, stable_iters = -1, 0\n",
    "        for _ in range(60):  # ~30s max\n",
    "            anchors = driver.find_elements(By.TAG_NAME, \"a\")\n",
    "            count = len(anchors)\n",
    "            if count == prev_count:\n",
    "                stable_iters += 1\n",
    "            else:\n",
    "                stable_iters = 0\n",
    "            prev_count = count\n",
    "            if stable_iters >= 4:  # stable ~2s\n",
    "                break\n",
    "            time.sleep(0.5)\n",
    "\n",
    "        soup = BeautifulSoup(driver.page_source, \"lxml\")\n",
    "\n",
    "        # collect document-like links\n",
    "        seen_urls = set()\n",
    "        for a in soup.find_all(\"a\", href=True):\n",
    "            href = a[\"href\"]\n",
    "            text = (a.get_text(strip=True) or \"\").strip()\n",
    "            full = urljoin(driver.current_url, href)\n",
    "            if not is_doc_href(full):\n",
    "                continue\n",
    "            if full in seen_urls:\n",
    "                continue\n",
    "            seen_urls.add(full)\n",
    "            name = text or (urlparse(full).path.rsplit(\"/\", 1)[-1] or \"document\")\n",
    "            if should_skip(name):\n",
    "                continue\n",
    "            rows.append({\n",
    "                \"application_number\": app_id,\n",
    "                \"file_name\": name,\n",
    "                \"url\": full\n",
    "            })\n",
    "\n",
    "    except Exception as e:\n",
    "        # Record the failure so you can inspect later\n",
    "        rows.append({\n",
    "            \"application_number\": app_id,\n",
    "            \"file_name\": \"__ERROR__\",\n",
    "            \"url\": f\"{type(e).__name__}: {e}\"\n",
    "        })\n",
    "    finally:\n",
    "        driver.quit()\n",
    "        time.sleep(0.8)  # be polite\n",
    "\n",
    "# Build the flat DataFrame\n",
    "files_df = pd.DataFrame(rows)\n",
    "\n",
    "# Optional: remove error rows if any\n",
    "files_df = files_df[files_df[\"file_name\"] != \"__ERROR__\"].reset_index(drop=True)\n",
    "\n",
    "# Show without truncation in notebooks/terminals\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "print(files_df)\n",
    "\n",
    "# Save for later use\n",
    "# files_df.to_csv(\"02_fileNameAndDocUrl.csv\", index=False)\n",
    "# files_df.to_parquet(\"02_fileNameAndDocUrl.parquet\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [application_number, file_name, url]\n",
      "Index: []\n",
      "\n",
      "Number of matching rows: 0\n",
      "Original DataFrame had 7 rows\n"
     ]
    }
   ],
   "source": [
    "## Filter FileNames\n",
    "# search_terms = [\n",
    "#     \"Report\", \"Decision Notice\", \"Surrey Highways\", \"National Trust\", \"Surrey County Council\", \"Statutory Correspondence\", \"Appeal\", \"Decision\", \"Rebuttal\"\n",
    "# ]\n",
    "# pattern = '|'.join(search_terms)  \n",
    "# filtered_df = files_df[files_df['file_name'].str.contains(pattern, case=False, na=False)]\n",
    "# print(filtered_df)\n",
    "# print(f\"\\nNumber of matching rows: {len(filtered_df)}\")\n",
    "# print(f\"Original DataFrame had {len(files_df)} rows\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
